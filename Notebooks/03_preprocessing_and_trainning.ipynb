{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "80628d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c0e8f8",
   "metadata": {},
   "source": [
    "# Load data and features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dfec78da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path_data = '../Data/'\n",
    "\n",
    "#list of all data names\n",
    "city_data = ['jc_listings','jc_locale',\n",
    "             'nyc_listings','nyc_locale',\n",
    "             'rio_listings','rio_locale']\n",
    "                   \n",
    "dfs = {}\n",
    "\n",
    "# loop to load all the data with respective name\n",
    "for city in city_data:\n",
    "    dfs[city] = pd.read_pickle(path_data+city+'.pkl')    \n",
    "    \n",
    "for key,val in dfs.items():\n",
    "    exec(key + '=val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d184d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete dfs dictionary to free memory\n",
    "del dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9bcfb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['neighbourhood_cleansed', 'latitude','longitude','room_type','bedrooms', 'beds',\n",
    "            'accommodates', 'review_scores_rating', 'review_scores_cleanliness',\n",
    "            'review_scores_location', 'review_scores_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f247770",
   "metadata": {},
   "source": [
    "# Preprocesses Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac013d37",
   "metadata": {},
   "source": [
    "Selecting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "2d6c0460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2028 entries, 0 to 2565\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   neighbourhood_cleansed     2028 non-null   object \n",
      " 1   latitude                   2028 non-null   float64\n",
      " 2   longitude                  2028 non-null   float64\n",
      " 3   room_type                  2028 non-null   object \n",
      " 4   bedrooms                   1858 non-null   float64\n",
      " 5   beds                       1973 non-null   float64\n",
      " 6   accommodates               2028 non-null   int64  \n",
      " 7   review_scores_rating       1708 non-null   float64\n",
      " 8   review_scores_cleanliness  1706 non-null   float64\n",
      " 9   review_scores_location     1706 non-null   float64\n",
      " 10  review_scores_value        1706 non-null   float64\n",
      "dtypes: float64(8), int64(1), object(2)\n",
      "memory usage: 190.1+ KB\n",
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 2028 entries, 0 to 2565\n",
      "Series name: price\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "2028 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 31.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jersey City data\n",
    "\n",
    "jc_features = jc_listings[features]\n",
    "jc_target = jc_listings.price\n",
    "\n",
    "jc_features.info() , jc_target.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "3bea9be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23248 entries, 0 to 26365\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   neighbourhood_cleansed     23248 non-null  object \n",
      " 1   latitude                   23248 non-null  float64\n",
      " 2   longitude                  23248 non-null  float64\n",
      " 3   room_type                  23248 non-null  object \n",
      " 4   bedrooms                   22119 non-null  float64\n",
      " 5   beds                       23068 non-null  float64\n",
      " 6   accommodates               23248 non-null  int64  \n",
      " 7   review_scores_rating       17147 non-null  float64\n",
      " 8   review_scores_cleanliness  16973 non-null  float64\n",
      " 9   review_scores_location     16973 non-null  float64\n",
      " 10  review_scores_value        16973 non-null  float64\n",
      "dtypes: float64(8), int64(1), object(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " <bound method Series.info of 0        3500.0\n",
       " 1        5000.0\n",
       " 2         681.0\n",
       " 3        8999.0\n",
       " 4         500.0\n",
       "           ...  \n",
       " 26361     115.0\n",
       " 26362     149.0\n",
       " 26363      60.0\n",
       " 26364     320.0\n",
       " 26365     657.0\n",
       " Name: price, Length: 23248, dtype: float64>)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rio data\n",
    "\n",
    "rio_features = rio_listings[features]\n",
    "rio_target = rio_listings.price\n",
    "\n",
    "rio_features.info(), rio_target.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "636ed2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22618 entries, 0 to 39879\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   neighbourhood_cleansed     22618 non-null  object \n",
      " 1   latitude                   22618 non-null  float64\n",
      " 2   longitude                  22618 non-null  float64\n",
      " 3   room_type                  22618 non-null  object \n",
      " 4   bedrooms                   20569 non-null  float64\n",
      " 5   beds                       22156 non-null  float64\n",
      " 6   accommodates               22618 non-null  int64  \n",
      " 7   review_scores_rating       19108 non-null  float64\n",
      " 8   review_scores_cleanliness  19083 non-null  float64\n",
      " 9   review_scores_location     19083 non-null  float64\n",
      " 10  review_scores_value        19083 non-null  float64\n",
      "dtypes: float64(8), int64(1), object(2)\n",
      "memory usage: 2.1+ MB\n",
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 22618 entries, 0 to 39879\n",
      "Series name: price\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "22618 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 353.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New York City data\n",
    "\n",
    "nyc_features = nyc_listings[features]\n",
    "nyc_target = nyc_listings.price\n",
    "\n",
    "nyc_features.info(), nyc_target.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0452be",
   "metadata": {},
   "source": [
    "Processing pipeline for numeric and categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ee9cc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Pipeline\n",
    "\n",
    "num_atributes = ['latitude','longitude', 'bedrooms', 'beds',\n",
    "            'accommodates', 'review_scores_rating', 'review_scores_cleanliness',\n",
    "            'review_scores_location', 'review_scores_value']\n",
    "\n",
    "cat_atributes = ['neighbourhood_cleansed', 'room_type']\n",
    "\n",
    "num_steps = [(\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"median\")), \n",
    "            (\"scaler\", StandardScaler())]\n",
    "\n",
    "cat_steps = [(\"one_hot\", OneHotEncoder(handle_unknown= 'ignore'))]\n",
    "\n",
    "# data pipeline\n",
    "\n",
    "num_pipeline = Pipeline(num_steps)\n",
    "cat_pipeline = Pipeline(cat_steps)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "                (\"num\", num_pipeline, num_atributes),\n",
    "                (\"cat\", cat_pipeline, cat_atributes)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6ea189",
   "metadata": {},
   "source": [
    "# Jersey City"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d574e6",
   "metadata": {},
   "source": [
    "## Train test split and Base Models fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "a54308e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# JC\n",
    "\n",
    "X = jc_features\n",
    "y = np.log(jc_target)\n",
    "\n",
    "jc_X_train,jc_X_test,jc_y_train,jc_y_test = train_test_split(X,y, test_size=0.3, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "bb6cc28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models fit\n",
    "\n",
    "pipe_1 = Pipeline(steps = [(\"preprocess\",preprocessor),(\"model\", Lasso(alpha=.1))])\n",
    "pipe_2 = Pipeline(steps = [(\"preprocess\",preprocessor),(\"model\", LinearRegression())])\n",
    "pipe_3 = Pipeline(steps = [(\"preprocess\",preprocessor),(\"model\", RandomForestRegressor())])\n",
    "pipe_4 = Pipeline(steps = [(\"preprocess\",preprocessor),(\"model\", xgb.XGBRegressor(eval_metric = 'rmse'))])\n",
    "\n",
    "jc_Lasso = pipe_1.fit(jc_X_train, jc_y_train)\n",
    "jc_LR = pipe_2.fit(jc_X_train, jc_y_train)\n",
    "jc_RFR = pipe_3.fit(jc_X_train, jc_y_train)\n",
    "jc_XGB = pipe_4.fit(jc_X_train, jc_y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc2d03",
   "metadata": {},
   "source": [
    "# Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "b95090c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model valuation\n",
    "\n",
    "model_score = [jc_Lasso.score(jc_X_test, jc_y_test), \n",
    "               jc_LR.score(jc_X_test, jc_y_test), \n",
    "               jc_RFR.score(jc_X_test, jc_y_test),\n",
    "               jc_XGB.score(jc_X_test, jc_y_test)]\n",
    "\n",
    "predictions = (pipe_1.predict(jc_X_test), pipe_2.predict(jc_X_test), pipe_3.predict(jc_X_test),  pipe_4.predict(jc_X_test))\n",
    "\n",
    "jc_rmse = []\n",
    "for pred in predictions:\n",
    "    jc_rmse.append(np.sqrt(mean_squared_error(np.exp(jc_y_test),np.exp(pred))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "46886431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5477949585905698, 0.6351097381033965, 0.7505826186448199, 0.7369438567703941] \n",
      " [302.2103659249311, 263.3429525934947, 224.30621776018404, 220.85283044485166]\n"
     ]
    }
   ],
   "source": [
    "print(model_score, '\\n',jc_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa9b8f",
   "metadata": {},
   "source": [
    "Best models are Random Forest Regressor and XGB; We will optimize these two models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c145eeaf",
   "metadata": {},
   "source": [
    "# Grid search and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "410f7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB GridSearchCV\n",
    "xgb_params = {'model__n_estimators': range(50,250,25),\n",
    "              'model__max_depth' : range(2,10,1),\n",
    "              \"model__min_child_weight\":range(1, 5,1),\n",
    "              'model__learning_rate': [0.1, 0.01]}\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator = pipe_4,\n",
    "                        param_grid = xgb_params,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        n_jobs = 10,\n",
    "                        cv = 5)\n",
    "\n",
    "xgb_grid.fit(jc_X_train, jc_y_train)\n",
    "\n",
    "jc_xgb_grid = xgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "69626f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__min_child_weight': 4, 'model__n_estimators': 150} \n",
      " -0.15875810827216283\n"
     ]
    }
   ],
   "source": [
    "print(xgb_grid.best_params_, '\\n', xgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "e5e76990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['latitude',\n",
       "                                                                          'longitude',\n",
       "                                                                          'bedrooms',\n",
       "                                                                          'beds',\n",
       "                                                                          'accommodates',\n",
       "                                                                          'review_scores_rating',\n",
       "                                                                          'review_scores_cleanliness',\n",
       "                                                                          'review_scores_location',\n",
       "                                                                          'review_scores_value']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('one_hot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['neighbourhood_cleansed',\n",
       "                                                                          'room_type'])])),\n",
       "                                       ('model', RandomForestRegressor())]),\n",
       "             n_jobs=10,\n",
       "             param_grid={'model__max_depth': range(2, 10),\n",
       "                         'model__max_features': ['sqrt', 'log2', None],\n",
       "                         'model__min_samples_split': range(2, 10),\n",
       "                         'model__n_estimators': range(50, 250, 25)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest GridSearchCV\n",
    "\n",
    "rfr_params = {'model__n_estimators': range(50,250,25),\n",
    "              'model__max_features': ['sqrt', 'log2', None],\n",
    "              'model__max_depth' : range(2,10,1),\n",
    "              'model__min_samples_split' : range(2,10,1)}\n",
    "\n",
    "rfr_grid = GridSearchCV(estimator = pipe_3,\n",
    "                        param_grid = rfr_params,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        n_jobs = 10,\n",
    "                        cv = 5)\n",
    "\n",
    "rfr_grid.fit(jc_X_train, jc_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "a439d33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 9, 'model__max_features': None, 'model__min_samples_split': 7, 'model__n_estimators': 75} \n",
      " -0.16399165516925676\n"
     ]
    }
   ],
   "source": [
    "print(rfr_grid.best_params_, '\\n', rfr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5ad052",
   "metadata": {},
   "source": [
    "# Rio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e067d6ff",
   "metadata": {},
   "source": [
    "## Train test split and Base Models fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "b9520150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# Rio\n",
    "\n",
    "X = rio_features\n",
    "y = np.log(rio_target)\n",
    "\n",
    "rio_X_train,rio_X_test,rio_y_train,rio_y_test = train_test_split(X,y, test_size=0.3, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "10a79268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit\n",
    "\n",
    "rio_Lasso = pipe_1.fit(rio_X_train, rio_y_train)\n",
    "rio_LR = pipe_2.fit(rio_X_train, rio_y_train)\n",
    "rio_RFR = pipe_3.fit(rio_X_train, rio_y_train)\n",
    "rio_XGB = pipe_4.fit(rio_X_train, rio_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1358ae",
   "metadata": {},
   "source": [
    "## Madels Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "98ae140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model valuation\n",
    "\n",
    "model_score = [rio_Lasso.score(rio_X_test, rio_y_test), \n",
    "               rio_LR.score(rio_X_test, rio_y_test), \n",
    "               rio_RFR.score(rio_X_test, rio_y_test),\n",
    "               rio_XGB.score(rio_X_test, rio_y_test)]\n",
    "\n",
    "predictions = (pipe_1.predict(rio_X_test), pipe_2.predict(rio_X_test), pipe_3.predict(rio_X_test),  pipe_4.predict(rio_X_test))\n",
    "\n",
    "rio_rmse = []\n",
    "for pred in predictions:\n",
    "    rio_rmse.append(np.sqrt(mean_squared_error(np.exp(rio_y_test),np.exp(pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "c5187bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31063110930823756, 0.3847420931339789, 0.5159466668490591, 0.5467374553953794] \n",
      " [61670.36993046871, 456646.03195124416, 898.5844133169879, 895.731505013148]\n"
     ]
    }
   ],
   "source": [
    "print(model_score, '\\n',rio_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a57f3",
   "metadata": {},
   "source": [
    "Best models are Random Forest Regressor and XGB; We will optimize these two models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236aa6b",
   "metadata": {},
   "source": [
    "## Grid search and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "a012870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB GridSearchCV\n",
    "xgb_params = {'model__n_estimators': range(50,250,25),\n",
    "              'model__max_depth' : range(2,10,1),\n",
    "              \"model__min_child_weight\":range(1, 5,1),\n",
    "              'model__learning_rate': [0.1, 0.01]}\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator = pipe_4,\n",
    "                        param_grid = xgb_params,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        n_jobs = 10,\n",
    "                        cv = 5)\n",
    "\n",
    "xgb_grid.fit(rio_X_train, rio_y_train)\n",
    "\n",
    "rio_xgb_grid = xgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "5c8ad34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__min_child_weight': 4, 'model__n_estimators': 225} \n",
      " -0.39523579162018735\n"
     ]
    }
   ],
   "source": [
    "print(xgb_grid.best_params_, '\\n', xgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "1fff7338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['latitude',\n",
       "                                                                          'longitude',\n",
       "                                                                          'bedrooms',\n",
       "                                                                          'beds',\n",
       "                                                                          'accommodates',\n",
       "                                                                          'review_scores_rating',\n",
       "                                                                          'review_scores_cleanliness',\n",
       "                                                                          'review_scores_location',\n",
       "                                                                          'review_scores_value']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('one_hot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['neighbourhood_cleansed',\n",
       "                                                                          'room_type'])])),\n",
       "                                       ('model', RandomForestRegressor())]),\n",
       "             n_jobs=10,\n",
       "             param_grid={'model__max_depth': range(2, 10),\n",
       "                         'model__max_features': ['sqrt', 'log2', None],\n",
       "                         'model__min_samples_split': range(2, 10),\n",
       "                         'model__n_estimators': range(50, 250, 25)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest GridSearchCV\n",
    "\n",
    "rfr_params = {'model__n_estimators': range(50,250,25),\n",
    "              'model__max_features': ['sqrt', 'log2', None],\n",
    "              'model__max_depth' : range(2,10,1),\n",
    "              'model__min_samples_split' : range(2,10,1)}\n",
    "\n",
    "rfr_grid = GridSearchCV(estimator = pipe_3,\n",
    "                        param_grid = rfr_params,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        n_jobs = 10,\n",
    "                        cv = 5)\n",
    "\n",
    "rfr_grid.fit(rio_X_train, rio_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "9434879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 9, 'model__max_features': None, 'model__min_samples_split': 8, 'model__n_estimators': 175} \n",
      " -0.4203439067993762\n"
     ]
    }
   ],
   "source": [
    "print(rfr_grid.best_params_, '\\n', rfr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26aca88",
   "metadata": {},
   "source": [
    "# New York City"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec6591e",
   "metadata": {},
   "source": [
    "## Train test split and Base Models fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "4d0bdb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# NYC\n",
    "\n",
    "X = nyc_features\n",
    "y = np.log(nyc_target)\n",
    "\n",
    "nyc_X_train,nyc_X_test,nyc_y_train,nyc_y_test = train_test_split(X,y, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "da2124ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit\n",
    "\n",
    "nyc_Lasso = pipe_1.fit(nyc_X_train, nyc_y_train)\n",
    "nyc_LR = pipe_2.fit(nyc_X_train, nyc_y_train)\n",
    "nyc_RFR = pipe_3.fit(nyc_X_train, nyc_y_train)\n",
    "nyc_XGB = pipe_4.fit(nyc_X_train, nyc_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba7206",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b23c932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model valuation\n",
    "\n",
    "model_score = [nyc_Lasso.score(nyc_X_test, nyc_y_test), \n",
    "               nyc_LR.score(nyc_X_test, nyc_y_test), \n",
    "               nyc_RFR.score(nyc_X_test, nyc_y_test),\n",
    "               nyc_XGB.score(nyc_X_test, nyc_y_test)]\n",
    "\n",
    "predictions = (pipe_1.predict(nyc_X_test), pipe_2.predict(nyc_X_test), pipe_3.predict(nyc_X_test),  pipe_4.predict(nyc_X_test))\n",
    "\n",
    "nyc_rmse = []\n",
    "for pred in predictions:\n",
    "    nyc_rmse.append(np.sqrt(mean_squared_error(np.exp(nyc_y_test),np.exp(pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1845bd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36643840475311906, 0.6064484959655556, 0.687967085370149, 0.6743843920858883] \n",
      " [369.67368645053665, 354.1918112749847, 335.5799557379308, 338.7298315145673]\n"
     ]
    }
   ],
   "source": [
    "print(model_score, '\\n',nyc_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaaedf0",
   "metadata": {},
   "source": [
    "## Grid search and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "d4098a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search and cross validation:\n",
    "# XGB GridSearchCV\n",
    "xgb_params = {'model__n_estimators': range(50,250,25),\n",
    "              'model__max_depth' : range(2,10,1),\n",
    "              \"model__min_child_weight\":range(1, 5,1),\n",
    "              'model__learning_rate': [0.1, 0.01]}\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator = pipe_4,\n",
    "                        param_grid = xgb_params,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        n_jobs = 10,\n",
    "                        cv = 5)\n",
    "\n",
    "xgb_grid.fit(nyc_X_train, nyc_y_train)\n",
    "\n",
    "nyc_xgb_grid = xgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "3e94c1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__learning_rate': 0.1, 'model__max_depth': 9, 'model__min_child_weight': 2, 'model__n_estimators': 175} \n",
      " -0.17606517179736997\n"
     ]
    }
   ],
   "source": [
    "print(xgb_grid.best_params_, '\\n', xgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "63bb5f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['latitude',\n",
       "                                                                          'longitude',\n",
       "                                                                          'bedrooms',\n",
       "                                                                          'beds',\n",
       "                                                                          'accommodates',\n",
       "                                                                          'review_scores_rating',\n",
       "                                                                          'review_scores_cleanliness',\n",
       "                                                                          'review_scores_location',\n",
       "                                                                          'review_scores_value']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('one_hot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['neighbourhood_cleansed',\n",
       "                                                                          'room_type'])])),\n",
       "                                       ('model', RandomForestRegressor())]),\n",
       "             n_jobs=10,\n",
       "             param_grid={'model__max_depth': range(2, 10),\n",
       "                         'model__max_features': ['sqrt', 'log2', None],\n",
       "                         'model__min_samples_split': range(2, 10),\n",
       "                         'model__n_estimators': range(50, 250, 25)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest GridSearchCV\n",
    "\n",
    "rfr_params = {'model__n_estimators': range(50,250,25),\n",
    "              'model__max_features': ['sqrt', 'log2', None],\n",
    "              'model__max_depth' : range(2,10,1),\n",
    "              'model__min_samples_split' : range(2,10,1)}\n",
    "\n",
    "rfr_grid = GridSearchCV(estimator = pipe_3,\n",
    "                        param_grid = rfr_params,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        n_jobs = 10,\n",
    "                        cv = 5)\n",
    "\n",
    "rfr_grid.fit(nyc_X_train, nyc_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "fcb4941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 9, 'model__max_features': None, 'model__min_samples_split': 7, 'model__n_estimators': 175} \n",
      " -0.19203295852787533\n"
     ]
    }
   ],
   "source": [
    "print(rfr_grid.best_params_, '\\n', rfr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be05e79",
   "metadata": {},
   "source": [
    "XGBoosting Regression consistently out perfrom Random Forest Regression for the three case studies. Next we will build the best model for each city, measure its performance and save the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522c082",
   "metadata": {},
   "source": [
    "## Final Model Selection¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d3778",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "93b537da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        R²        rmse\n",
      "JC   75.37  220.627080\n",
      "Rio  55.68  912.965461\n",
      "NYC  69.16  337.548466\n"
     ]
    }
   ],
   "source": [
    "model_score = [round(jc_xgb_grid.score(jc_X_test, jc_y_test)*100,2), \n",
    "               round(rio_xgb_grid.score(rio_X_test, rio_y_test)*100,2), \n",
    "               round(nyc_xgb_grid.score(nyc_X_test, nyc_y_test)*100,2)]\n",
    "\n",
    "predictions = (jc_xgb_grid.predict(jc_X_test), \n",
    "               rio_xgb_grid.predict(rio_X_test),\n",
    "               nyc_xgb_grid.predict(nyc_X_test))\n",
    "test_data = [jc_y_test, rio_y_test, nyc_y_test]\n",
    "               \n",
    "models_rmse = []\n",
    "for pred, data in zip(predictions, test_data):\n",
    "    models_rmse.append(np.sqrt(mean_squared_error(np.exp(data),np.exp(pred))))\n",
    "    \n",
    "data = {'R\\u00b2': model_score, 'rmse': models_rmse}\n",
    "cities = ['JC', 'Rio', 'NYC']\n",
    "\n",
    "performance = pd.DataFrame(data,index = cities)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bdcf20",
   "metadata": {},
   "source": [
    "Grid Search hyperparameters optimization improved all XBoost models coeficient of determination. Jersey City root mean squared error (rmse) was marginaly improved while Rio and New York City were marginally worse. These results increase our confidense that the models aren't overfiting the current data. Note Rio rmse is larger than the rest because it is quoted in Brazilian Reais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68647b8c",
   "metadata": {},
   "source": [
    "## Save best model object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "a9b5b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# JC\n",
    "\n",
    "jc_best_model = jc_xgb_grid\n",
    "jc_best_model.version = '1.0'\n",
    "jc_best_model.pandas_version = pd.__version__\n",
    "jc_best_model.numpy_version = np.__version__\n",
    "jc_best_model.xgb_version = xgb.__version__\n",
    "jc_best_model.X_columns = [col for col in jc_X_train.columns]\n",
    "jc_best_model.build_datetime = datetime.datetime.now()\n",
    "\n",
    "# Rio\n",
    "\n",
    "rio_best_model = rio_xgb_grid\n",
    "rio_best_model.version = '1.0'\n",
    "rio_best_model.pandas_version = pd.__version__\n",
    "rio_best_model.numpy_version = np.__version__\n",
    "rio_best_model.xgb_version = xgb.__version__\n",
    "rio_best_model.X_columns = [col for col in jc_X_train.columns]\n",
    "rio_best_model.build_datetime = datetime.datetime.now()\n",
    "\n",
    "# NYC\n",
    "\n",
    "nyc_best_model = jc_xgb_grid\n",
    "nyc_best_model.version = '1.0'\n",
    "nyc_best_model.pandas_version = pd.__version__\n",
    "nyc_best_model.numpy_version = np.__version__\n",
    "nyc_best_model.xgb_version = xgb.__version__\n",
    "nyc_best_model.X_columns = [col for col in jc_X_train.columns]\n",
    "nyc_best_model.build_datetime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "75ca5293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../modelsnyc_pricing_model.pkl']"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "import joblib\n",
    "modelpath = '../models'\n",
    "\n",
    "joblib.dump(jc_best_model, modelpath+'jc_pricing_model.pkl')\n",
    "joblib.dump(rio_best_model, modelpath+'rio_pricing_model.pkl')\n",
    "joblib.dump(nyc_best_model, modelpath+'nyc_pricing_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
